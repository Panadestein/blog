#+TITLE: Strips from the BQNcrate
#+INCLUDE: "../html-head.org"
#+HTML_HEAD: <style>
#+HTML_HEAD:   #table-of-contents > h2 { display: none; } /* Hide the default TOC heading */
#+HTML_HEAD:   #table-of-contents > ul { display: block; } /* Ensure TOC content is shown */
#+HTML_HEAD: </style>

The [[https://mlochbaum.github.io/bqncrate/][BQNcrate]] is an useful tool for learning and honing BQN skills, though not all of its entries are easy to understand.
Personally, I always prefer a shorter implementation if it's possible to maintain the same time complexity.
For this post, I have chosen three examples that fall into that specific category of code where you can read every primitive,
know exactly what each one does, but still miss the emergent behavior of the composition.

#+TOC: headlines 1 :ignore-title t

** Topological sort

Seeing this implementation of [[https://en.wikipedia.org/wiki/Topological_sorting#Kahn's_algorithm][Kahn's algorithm]] for the first time is not for the faint of heart:

#+begin_src bqn :tangle ../bqn/bc.bqn :exports code
  TC ‚Üê {{ùïä‚çü(ùï©<‚óã‚â†‚ä¢)‚üú(ùï©‚àæ¬∑/ùï®‚ä∏<)ùï®‚à®‚àß¬¥‚àò‚äè‚üúùï®¬®p}‚üú/0¬®p‚Üêùï©}
#+end_src

#+RESULTS:
: (function block)

To understand dense, beautiful code like this, a good first step is to refactor it into smaller block functions
and named variables. Let's deconstruct the magic:

#+begin_src bqn :tangle ../bqn/bc.bqn :exports code
  TCS ‚Üê {ùïägraph:
    result‚Äømask ‚Üê ‚ü®‚ü© ‚ãà 0¬®graph
    Sort ‚Üê {mùïär:
      n ‚Üê m‚à®ready ‚Üê {‚àß¬¥ùï©‚äèm}¬®graph
      n ùïä‚çü(ùï©‚ä∏‚â¢) r‚àæ/m<ready
    }
    mask Sort result
  }
#+end_src

#+RESULTS:
: (function block)

Let's verify our refactoring is equivalent to the original. The input for both functions is a list of lists
representing the dependency graph: each index is a task, and its corresponding element is a list of
its prerequisites. For example:

#+begin_src bqn :tangle ../bqn/bc.bqn :exports code
  graph ‚Üê ‚ü®‚ü©‚Äø‚ü®‚ü©‚Äø‚ü®0‚ü©‚Äø‚ü®0,1‚ü©‚Äø‚ü®2,3‚ü©‚Äø‚ü®4‚ü©‚Äø‚ü®4‚ü©‚Äø‚ü®1,5,6‚ü©
#+end_src

#+RESULTS:
: ‚ü® ‚ü®‚ü© ‚ü®‚ü© ‚ü® 0 ‚ü© ‚ü® 0 1 ‚ü© ‚ü® 2 3 ‚ü© ‚ü® 4 ‚ü© ‚ü® 4 ‚ü© ‚ü® 1 5 6 ‚ü© ‚ü©

And then:

#+begin_src bqn :tangle ../bqn/bc.bqn :exports both
  (TC‚â°TCS) graph
#+end_src

#+RESULTS:
: 1

Looks good. So, how does this more "readable" version work? The algorithm's state is propagated through two variables:
a "can-be-built" boolean mask =m=, initially all false, and the final sorted list =s=,
initially empty (indices =/= of a zeros' list is an empty list).

The =Sort= function then begins its iterative process. Inside, it first identifies the ready nodes: those whose
prerequisites are all satisfied by the current mask =m=. In the first step, this naturally selects nodes with
no prerequisites =‚ü®‚ü©=, which unlocks the next layer of dependencies. The new "can-be-built" mask =n= is the union
of the old mask and the newly ready nodes, ensuring it grows monotonically.

Crucially, the result list is extended only with the nodes that just became available. This new layer is
isolated with the differential comparison =m<n= (=m<ready= also works, since =n‚â°m‚à®ready=), and their
indices =/= are appended to the result before recurring with the updated state. The process repeats until a pass yields
no new nodes, completing the sort.

** The _‚Äãwhile_ modifier

This one was infamously hard for me to grasp, and reading its [[https://mlochbaum.github.io/BQN/doc/control.html#low-stack-version][docs]] didn't clarify much at first. To understand it,
you need to be familiar with a fair bit of BQN, especially the functional programming and combinators aspects.
What makes it so complicated is the use of modifier recursion, which I will try to break down here.

An unrolling of the first two steps reveals that up to =2‚ãÜn= evaluations of =ùîΩ= can occur at recursion
level =n=. This is derived by noting that, within the BQN combinator, the left function of the
rightmost atop dictates that the =ùîΩ= for the subsequent step is, in accordance to =ùîΩ_ùï£_ùîæ=:

#+begin_src bqn :tangle ../bqn/bc.bqn
  _w0_ ‚Üê {ùîΩ‚çüùîæ‚àòùîΩ_ùï£_ùîæ‚àòùîΩ‚çüùîæùï©}
  _w1_ ‚Üê {(ùîΩ‚çüùîæ‚àòùîΩ)‚çüùîæ‚àò(ùîΩ‚çüùîæ‚àòùîΩ)_w0_ùîæ‚àò(ùîΩ‚çüùîæ‚àòùîΩ)‚çüùîæùï©}
  _w2_ ‚Üê {((ùîΩ‚çüùîæ‚àòùîΩ)‚çüùîæ‚àò(ùîΩ‚çüùîæ‚àòùîΩ))‚çüùîæ‚àò((ùîΩ‚çüùîæ‚àòùîΩ)‚çüùîæ‚àò(ùîΩ‚çüùîæ‚àòùîΩ))_w0_ùîæ‚àò((ùîΩ‚çüùîæ‚àòùîΩ)‚çüùîæ‚àò(ùîΩ‚çüùîæ‚àòùîΩ))‚çüùîæùï©}
#+end_src

Another way to clarify the concept is to implement the same logic both as a function
and as a 1-modifier, and then compare these implementations with the two 2-modifiers
(one exhibiting linear and the other a logarithmic number of stack frames):

#+begin_src bqn :tangle ../bqn/bc.bqn
  Whiles ‚Üê {F‚ÄøGùïäùï©:
    Wfun ‚Üê {ùïé‚çüG‚àòùïéÀô‚ä∏ùïä‚àòùïé‚çüGùï©}
    _wom ‚Üê {ùîΩ‚çüG‚àòùîΩ_ùï£‚àòùîΩ‚çüGùï©}
    _wtmlog_ ‚Üê {ùîΩ‚çüùîæ‚àòùîΩ_ùï£_ùîæ‚àòùîΩ‚çüùîæùï©}
    _wtmlin_ ‚Üê {ùïä‚àòùîΩ‚çüùîæùï©}
    ‚ü®f Wfun ùï©, f _wom ùï©, f _wtmlog_ g ùï©, f _wtmlin_ g ‚éä"SO"ùï©‚ü©
  }
#+end_src

#+RESULTS:
: (function block)

Let‚Äôs test it with a simple iteration that exceeds CBQN‚Äôs recursion limit, triggering a stack overflow:

#+begin_src bqn :tangle ../bqn/bc.bqn :exports both
  ‚ü®1‚ä∏+, 5000‚ä∏‚â•‚ü© Whiles 0
#+end_src

#+RESULTS:
: ‚ü® 5001 5001 5001 "SO" ‚ü©

** Levenshtein distance

The Levenshtein (or edit) [[https://en.wikipedia.org/wiki/Levenshtein_distance][distance]] is a measure of the similarity between two strings. It is defined
by the following recurrence, which is the basis of dynamic programming algorithms like Wagner-Fisher:

\begin{align*}
  d_{i0} &= i, \quad d_{0j} = j, \\
  d_{ij} &= \min \begin{cases} d_{i-1,j-1} + \mathbf{1}_{s_i \neq t_j} \\ d_{i-1,j} + 1 \\ d_{i,j-1} + 1 \end{cases}
\end{align*}

The Wagner-Fisher variant in the BQNcrate can be derived by shifting the distance matrix.
Given two strings \(s\) and \(t\) of lengths \(n\) and \(m\), respectively,
we define a new distance matrix as follows:

\begin{equation*}
  p_{ij} = d_{ij} + n - i + m - j
\end{equation*}

Under this transformation, the recurrence relation becomes:

\begin{align*}
  p_{i0} &= p_{0j} = m + n, \\
  p_{ij} &= \min \begin{cases} p_{i-1,j-1} + \mathbf{1}_{s_i \neq t_j} - 2 \\ p_{i-1,j} \\ p_{i,j-1} \end{cases}
\end{align*}

The above recurrence can be easily identified in the 3-train's middle function, which is
folded over the table of the costs (table comparing the characters).
Note that we compare insertions and substitutions, and then we can do a min scan
over the result to get the deletions, which gives a vectorised implementation.

An interesting part of this solution is the construction of the cost table,
which is done by reversing \(t\). Given that the final result for  \(p_{ij}\) ‚Äã is located
in the bottom-right corner and we use =foldr=, I would have expected \(s\) to be the
one reversed instead. However, both methods are functionally equivalent, as the following
stochastic test suggests:

#+begin_src bqn :tangle ../bqn/bc.bqn :exports both
  _l ‚Üê {¬Ø1‚äë(1‚ä∏+‚•ä+)‚óã‚â†(‚åä`‚ä¢‚åä‚äè‚ä∏¬ª‚àò‚ä¢-0‚àæ1+‚ä£)ÀùùîΩ}
  T ‚Üê ‚åΩ‚ä∏(=‚åú)_l‚â°=‚åú‚üú‚åΩ_l
  T‚óã{@+97+ùï©‚Ä¢rand.Range 25}¬¥ 1e4‚Äø1e5
#+end_src

#+RESULTS:
: 1

The reason both approaches work lies in the inherent symmetries of the Levenshtein distance:

- \(L(s,t) = L(t,s)\)
- \(L(s,t) = L(\text{rev}(s),\text{rev}(t))\)
- \(L(\text{rev}(s),t) = L(s,\text{rev}(t))\)

#+INCLUDE: "../html-foot.org"
